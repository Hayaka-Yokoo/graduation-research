{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbe4f04-37d9-4c97-a5d3-579d8a5ab667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de936fa6-0342-4422-b8ab-aa51b8859f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import nvdiffrast.torch as dr\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115d86ab-673c-4b71-91a0-4f017ffe67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fn = 'assets/monalisa.png'\n",
    "h, w = 256, 256\n",
    "n_triangles = 1000\n",
    "base_lr = 0.03\n",
    "report_iterations = 10\n",
    "n_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6cc43f-2d12-4990-b784-d5c18bbae61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pil_img(img):\n",
    "    return Image.fromarray((img[0].clip(0,1).detach().cpu().numpy()*255).astype('uint8'))\n",
    "\n",
    "def show(img):\n",
    "    display(to_pil_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb431e16-ea2a-4238-94fa-d334d018e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Image.open(image_fn).resize((h, w)).convert('RGB')\n",
    "target = np.asarray(target)\n",
    "target = torch.from_numpy(target.astype('f') / 255).cuda()[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed7d2c3-aaea-4489-ae21-49956f3c3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "glctx = dr.RasterizeGLContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0395884-da73-4316-b11f-f96ee61d5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = (torch.rand(n_triangles, 3, 2) * 2 - 1).cuda()\n",
    "verts.requires_grad = True\n",
    "color = torch.rand(n_triangles, 4).float().cuda()\n",
    "color.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ec9ee6-2d47-486b-9b49-f4bdc42442bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = torch.arange(n_triangles * 3).reshape(-1, 3).int().cuda()\n",
    "def combine_layers(out, bg_noise=0.05):\n",
    "    canvas = torch.ones_like(out[0:1,:,:,0:3])\n",
    "    canvas = canvas + torch.randn_like(out[0:1,:,:,0:3]) * bg_noise\n",
    "    \n",
    "    canvas_box  = torch.ones_like(out[0:1,:,:,0:3])\n",
    "    for i in range(0, n_triangles):\n",
    "        alpha = out[i:i+1, ..., 3:4]\n",
    "        #if i > 150:\n",
    "        alpha = alpha * 0.1\n",
    "        draw_color = out[i:i+1, ..., 0:3]\n",
    "        canvas = canvas * (1 - alpha) + alpha * draw_color\n",
    "    \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960a5169-746b-4474-81c9-32f99e091e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(v, c, combine_layers_kwargs={}):\n",
    "    verts_norm = v \n",
    "    color_norm = c \n",
    "    m_ones = -torch.ones(n_triangles, 3, 1).cuda().float()\n",
    "    ones = torch.ones(n_triangles, 3, 1).cuda().float()\n",
    "    verts_in = torch.cat([verts_norm, m_ones, ones], dim =2) # [..., None, :]\n",
    "    colors = color_norm[:, None, :].repeat(1, 3, 1)\n",
    "    rast, _ = dr.rasterize(glctx, verts_in, faces, resolution=[h, w], grad_db=True)\n",
    "    out_inter, _ = dr.interpolate(colors, rast, faces)\n",
    "    out_layers = dr.antialias(out_inter, rast, verts_in, faces, pos_gradient_boost=1)\n",
    "    out = combine_layers(out_layers, **combine_layers_kwargs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a27053-80aa-4186-b962-21d8b47076ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimRateScheduler(object):\n",
    "    def __init__(self, total_iterations):\n",
    "        self.total_iterations = total_iterations\n",
    "        self.ramp_up_to = 1 / 20\n",
    "        self.ramp_down_from = 3 / 4\n",
    "    def get_lr_scale(self, c_iter):\n",
    "        t = c_iter / self.total_iterations\n",
    "        lr_ramp = min(1.0, (1.0 - t) / 0.25)\n",
    "        lr_ramp = 0.5 - 0.5 * np.cos(lr_ramp * np.pi)\n",
    "        lr_ramp = lr_ramp * min(1.0, t / 0.05)\n",
    "        return lr_ramp\n",
    "    def get_noise_scale(self, c_iter):\n",
    "        t = c_iter / self.total_iterations\n",
    "        if t > self.ramp_down_from:\n",
    "            return 0\n",
    "        else:\n",
    "            return ((self.ramp_down_from - t) / self.ramp_down_from)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293b6030-9769-4392-a5d0-56950d8e95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([verts, color], lr = base_lr)\n",
    "ors = OptimRateScheduler(total_iterations=n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09387e0e-8a9b-4b45-aa6e-3203b3e76a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_gif(fn, imgs, fps=12):\n",
    "    img, *imgs = imgs\n",
    "    with open(fn, 'wb') as fp_out:\n",
    "        img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
    "             save_all=True, duration=int(1000./fps), loop=0)\n",
    "        \n",
    "def save_as_frames(fn, imgs, overwrite=True):\n",
    "    # save to folder `fn` with sequenced filenames\n",
    "    os.makedirs(fn, exist_ok=True)\n",
    "    for i, img in enumerate(imgs):\n",
    "        this_fn = os.path.join(fn, f'{i:08}.png')\n",
    "        if overwrite or not os.path.exists(this_fn):\n",
    "            save_as_png(this_fn, img)\n",
    "\n",
    "def save_as_png(fn, img):\n",
    "    if not fn.endswith('.png'):\n",
    "        fn = f'{fn}.png'\n",
    "    img.save(fn)\n",
    "            \n",
    "def save_info_list(fn, info_list):\n",
    "    with open(fn, 'w') as fout:\n",
    "        list(map(lambda r: print(r, file=fout), info_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd856802",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'nvdiffrast_1000t_10000e'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "pil_img_list = []\n",
    "info_list = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    lr = ors.get_lr_scale(i) * base_lr\n",
    "    optim.param_groups[0]['lr'] = lr\n",
    "    noise_scale = (0.05 * ors.get_noise_scale(i))\n",
    "    verts_noise = torch.randn_like(verts) * noise_scale\n",
    "    color_noise = torch.randn_like(color) * noise_scale * 0.5\n",
    "    verts_in = verts + verts_noise\n",
    "    color_in = color + color_noise\n",
    "    out = render(verts, color_in, {'bg_noise': 0.05})\n",
    "    loss = ((out-target)**2).mean()\n",
    "    loss_view = ((out-target)**2).mean()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    if (i + 1) % report_iterations == 0:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            verts_in = verts\n",
    "            color_in = color\n",
    "            out = render(verts, color_in, {'bg_noise': 0.0})\n",
    "            wonoise_loss = ((out-target)**2).mean()\n",
    "\n",
    "        info = f\"[{datetime.now()}]   Iteration {i + 1}, lr {optim.param_groups[0]['lr']}, loss {loss.item()} loss (without noise) {wonoise_loss.item()}, loss_view {loss_view}\"\n",
    "        print(info)\n",
    "        info_list.append(info)\n",
    "        save_info_list(f'{save_dir}/log.txt', info_list)\n",
    "            \n",
    "        show(out)\n",
    "        pil_img_list.append(to_pil_img(out))\n",
    "        save_as_gif(f'{save_dir}/animate.gif', pil_img_list, fps=12)\n",
    "        save_as_frames(f'{save_dir}/animate.frames', pil_img_list)\n",
    "        \n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8f859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
